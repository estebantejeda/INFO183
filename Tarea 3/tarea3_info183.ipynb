{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrucciones generales <a class=\"tocSkip\"></a>\n",
    "\n",
    "1. Forme un grupo de **máximo dos estudiantes**\n",
    "1. Versione su trabajo usando un **repositorio <font color=\"red\">privado</font> de github**. Agregue a su compañero y a su profesor (usuario github: phuijse) en la pestaña *Settings/Manage access*. No se aceptarán consultas si la tarea no está en github. No se evaluarán tareas que no estén en github.\n",
    "1. Se evaluará el **resultado, la profundidad de su análisis y la calidad/orden de sus códigos** en base al último commit antes de la fecha y hora de entrega\". Se bonificará a quienes muestren un método de trabajo incremental y ordenado según el histórico de *commits*\n",
    "1. Sean honestos, ríganse por el [código de ética de la ACM](https://www.acm.org/about-acm/code-of-ethics-in-spanish)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3: Predicción de una serie de tiempo caótica\n",
    "\n",
    "En esta tarea se pide entrenar y evaluar un predictor para el sistema no-lineal [Mackey-Glass](https://en.wikipedia.org/wiki/Mackey-Glass_equations)\n",
    "\n",
    "Esta serie de tiempo se obtiene de la solución de la siguiente ecuación diferencial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dt} = \\beta \\frac{ y(t-\\tau)}{1 + y(t-\\tau)^{n}} - \\gamma y(t),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde el parámetro $\\tau$ controla el comportamiento dinámico de la serie de tiempo \n",
    "\n",
    "En esta tarea nos limitaremos en estudiar el caso con $n=10$, $\\gamma = 0.1$ y $\\beta = 0.2$\n",
    "\n",
    "El valor del parámetro $\\tau$ modifica el comportamiento dinámico del sistema, en particular se tiene que\n",
    "\n",
    "- $\\tau = 17$ el sistema tiene un comportamiento debilmente caótico\n",
    "- $\\tau = 30$ el sistema tiene un comportamiento fuertemente caótico\n",
    "\n",
    "La ecuación de diferencial anterior fue propuesta por Michael Mackey and Leon Glass en 1977 como modelo para procesos fisiológicos asociados a la [homeostasis](https://es.wikipedia.org/wiki/Homeostasis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código adjunto a esta tarea genera la serie de tiempo en función \n",
    "\n",
    "Se generan 1000 muestras de la serie de tiempo. Use los primeros 500 puntos para entrenar, los siguientes 250 puntos para calibrar los hiperparámetros y los últimos 250 para evaluar y comparar los filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pylab as plt\n",
    "from mackey import MackeyGlass\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import animation, patches\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "\n",
    "# Puede calcular el error medio cuadrático normalizado usando:\n",
    "NMSE = lambda y, yhat : np.sum((y - yhat)**2)/np.var(y)\n",
    "\n",
    "# Gráfico\n",
    "(t_train, y_train), (t_valid, y_valid), (t_test, y_test), ymg, t= MackeyGlass(tau=30.)\n",
    "fig, ax = plt.subplots(figsize=(6, 3), tight_layout=True)\n",
    "ax.plot(t_train, y_train, label='Entrenamiento')\n",
    "ax.plot(t_valid, y_valid, label='Validación')\n",
    "ax.plot(t_test, y_test, label='Prueba')\n",
    "ax.set_title('Serie de tiempo Mackey-Glass');\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## (45%) Predicción con algoritmo LMS\n",
    "\n",
    "1. Describa en detalle el algoritmo LMS e implemente un predictor a un paso basado en el **algoritmo LMS normalizado**\n",
    "1. Considere el caso $\\tau=17$. Entrene su predictor en el conjunto de entrenamiento y encuentre la combinación de parámetros $\\mu$ y $L$ que minimiza el NMSE en el conjunto de validación. Se recomienda realizar un barrido logarítmo para $\\mu$. Para $L$ pruebe al menos los siguientes valores [5, 10, 20, 30]. Comente sobre lo que observa.\n",
    "1. Repita el paso anterior para el caso $\\tau = 30$\n",
    "1. Compare los resultados obtenidos con cada serie de tiempo ($\\tau=17$ y $\\tau=30$). Muestre la predicción en el conjunto de prueba versus su valor real. Muestre también los residuos. Discuta y analice sus resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Describa en detalle el algoritmo LMS e implemente un predictor a un paso basado en el algoritmo LMS normalizado\n",
    "\n",
    "**1. Describa en detalle el algoritmo LMS e implemente un predictor a un paso basado en el algoritmo LMS normalizado**\n",
    "\n",
    "LMS es un algotimo utilizado en filtros adaptativos para encontrar los coeficientes del filtro que permiten obtener el valor mínimo esperado del cuadrado de la señal de error.\n",
    "- Es un algortimo simple. \n",
    "- A diferencia del filtro de Wiener, este no requiere el conocimiento de las características estadísticas del entorno en el que opera.\n",
    "- Es robusto en un sentido determinista, es decir, hay una única realización del algoritmo frente a perturbaciones ambientales desconocidas.\n",
    "- No requiere de la inversión de la matriz de correlación del regresor, por lo que es más simple que RLS.\n",
    "\n",
    "Resumen del algoritmo:\n",
    "\n",
    "- L: número de pasos (es decir, largo del filtro)\n",
    "- $\\mu$: taza de aprendizaje (tamaño del paso)\n",
    "\n",
    "**Inicialización**: elegir un valor apropiado para $\\widehat{w}(0)$ si es que se dispone de información acerca del vector de coeficientes del filtro. Si no, utilizar $\\widehat{w}(0) = 0$\n",
    "\n",
    "**Data**: Obetener $u(n)=[u((n),u(n-1)),...,u(n-M+1)]$ y $d(n) = $ respuesta deseada en el tiempo\n",
    "\n",
    "**Para calular**: $\\widehat{w}(n+1)$ = estimación del vector de peso (coeficientes del filtro) de derivación en el tiempo $n+1$\n",
    "\n",
    "**Calcular**: for n=0,1,2,.. calcular:\n",
    "\n",
    "- $e(n) = d(n) - y(n)$ que es el error de estimación actual\n",
    "- $\\widehat{w}(n+1) = \\widehat{w}(n) + \\mu u(n)e^*(n) $ que es es el valor ótimo w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor a un paso NLMS\n",
    "class Filtro_NLMS:\n",
    "    \n",
    "    def __init__(self, L, mu, delta=1e-6, winit=None):\n",
    "        self.L = L\n",
    "        self.w = np.zeros(shape=(L, ))\n",
    "        self.mu = mu\n",
    "        self.delta = delta\n",
    "        \n",
    "    def update(self, un, dn):\n",
    "        unorm = np.dot(un, un) + self.delta\n",
    "        yn = np.dot(self.w, un)\n",
    "        self.w += 2*self.mu*(dn - yn)*(un/unorm)\n",
    "        return yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE entrenamiento 330.0053, test 211.0294\n"
     ]
    }
   ],
   "source": [
    "(t_train, y_train), (t_valid, y_valid), (t_test, y_test), ymg, t = MackeyGlass(tau=17.)\n",
    "#t[:500], y_obs[:500]), (t[500:750], y_obs[500:750]), (t[750:], y_obs[750:]\n",
    "\n",
    "L = 10\n",
    "nlms = Filtro_NLMS(L=L , mu=0.09)\n",
    "len(y_train)\n",
    "\n",
    "y = np.append(y_train,[y_valid,y_test])\n",
    "\n",
    "# Entrenamiento\n",
    "u_pred = np.zeros(shape=(1000, ))\n",
    "for k in range(nlms.L, len(y_train)):\n",
    "    u_pred[k] = nlms.update(un=y[k-nlms.L:k],dn=y[k])\n",
    "\n",
    "# Valid\n",
    "for k in range(len(y_train), 1000):\n",
    "    u_pred[k] = np.dot(nlms.w,y[k-nlms.L:k])\n",
    "    \n",
    "# Test\n",
    "for l in range(len(y_valid), len(y_test)):\n",
    "    u_pred[l] = np.dot(nlms.w,y[l-nlms.L:l])\n",
    "    \n",
    "print(\"NMSE entrenamiento %0.4f, test %0.4f\" %(NMSE(ymg[nlms.L:500], u_pred[nlms.L:500]), \n",
    "                                                NMSE(ymg[500:1000], u_pred[500:1000])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Considere el caso $\\tau=17$. Entrene su predictor en el conjunto de entrenamiento y encuentre la combinación de parámetros $\\mu$ y $L$ que minimiza el NMSE en el conjunto de validación. Se recomienda realizar un barrido logarítmo para $\\mu$. Para $L$ pruebe al menos los siguientes valores [5, 10, 20, 30]. Comente sobre lo que observa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_lms(tau):\n",
    "    \n",
    "    (t_train, y_train), (t_valid, y_valid), (t_test, y_test), ymg, t = MackeyGlass(tau=tau)\n",
    "    \n",
    "    y = np.append(y_train,[y_valid,y_test])\n",
    "    m_r = np.linspace(0.,1.,num=1000)\n",
    "    L_r = [5,10,20,30]\n",
    "    for i in range(0,len(L_r)):\n",
    "        for j in range(0,len(m_r)):\n",
    "            nlms = Filtro_NLMS(L=L_r[i] , mu=m_r[j])\n",
    "            \n",
    "            u_pred = np.zeros(shape=(1000, ))\n",
    "            \n",
    "            for k in range(nlms.L, 500):\n",
    "                u_pred[k] = nlms.update(un=y[k-nlms.L:k],dn=y[k])\n",
    "            \n",
    "            for l in range(500, 750):\n",
    "                u_pred[l] = np.dot(nlms.w,y[l-nlms.L:l])\n",
    "\n",
    "            mr = (NMSE(ymg[500:750], u_pred[500:750]))\n",
    "            \n",
    "            if(i==0 and j ==0):\n",
    "                mse_min = mr\n",
    "                m_min = m_r[j]\n",
    "            \n",
    "            if(mse_min>mr):\n",
    "                mse_min = mr\n",
    "                m_min = m_r[j]\n",
    "\n",
    "        print(\"t= \",tau, \"L= ,\",L_r[i],\" el MSE mímimo es :\",mse_min ,\" y con mu: \", m_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=  17.0 L= , 5  el MSE mímimo es : 194.33660601265902  y con mu:  0.11411411411411411\n",
      "t=  17.0 L= , 10  el MSE mímimo es : 103.1323330570734  y con mu:  0.11811811811811812\n",
      "t=  17.0 L= , 20  el MSE mímimo es : 87.42120056287108  y con mu:  0.07407407407407407\n",
      "t=  17.0 L= , 30  el MSE mímimo es : 87.42120056287108  y con mu:  0.07407407407407407\n"
     ]
    }
   ],
   "source": [
    "opt_lms(17.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE entrenamiento 324.4706, prueba 175.5715\n"
     ]
    }
   ],
   "source": [
    "# Utilizando L =30 y mu=0.074 que resultó dar menor MSE\n",
    "L = 30\n",
    "mu = 0.074\n",
    "nlms = Filtro_NLMS(L=L , mu=mu)\n",
    "\n",
    "# Train\n",
    "u_pred = np.zeros(shape=(1000, ))\n",
    "for k in range(nlms.L, 500):\n",
    "    u_pred[k] = nlms.update(un=y[k-nlms.L:k],dn=y[k])\n",
    "\n",
    "# Test\n",
    "for l in range(500,1000):\n",
    "    u_pred[l] = np.dot(nlms.w,y[l-nlms.L:l])\n",
    "    \n",
    "print(\"NMSE entrenamiento %0.4f, prueba %0.4f\" %(NMSE(ymg[nlms.L:500], u_pred[nlms.L:500]), \n",
    "                                                NMSE(ymg[500:], u_pred[500:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0950e9d9e7b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                 NMSE(ymg[500:750], u_pred[500:750]),NMSE(ymg[750:], u_pred[750:])))\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0minteract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'interact' is not defined"
     ]
    }
   ],
   "source": [
    "def upd(mu, L):\n",
    "    \n",
    "    fig, ax = plt.subplots(3, figsize=(9, 5), tight_layout=True)\n",
    "    (t_train, y_train), (t_valid, y_valid), (t_test, y_test), ymg, t = MackeyGlass(tau=17.)\n",
    "    nlms = Filtro_NLMS(L=L , mu=mu)\n",
    "    \n",
    "    y = np.append(y_train,[y_valid,y_test])\n",
    "\n",
    "    u_pred = np.zeros(shape=(1000, ))\n",
    "    for k in range(nlms.L, len(y_train)):\n",
    "        u_pred[k] = nlms.update(un=y[k-nlms.L:k],dn=y[k])\n",
    "\n",
    "    # Prueba\n",
    "    for k in range(500, 1000):\n",
    "        u_pred[k] = np.dot(nlms.w,y[k-nlms.L:k])\n",
    "        \n",
    "\n",
    "    ax[0].plot(t ,y,'k.', alpha=0.5, label='Observado'); ax[0].legend(); \n",
    "    ax[1].plot(t , ymg, 'g-', alpha=0.5, lw=2, label='Intrínseco', c='y'); \n",
    "    ax[1].plot(t[:500], u_pred[:500], alpha=0.75, lw=2, label='Predicho train'); \n",
    "    ax[1].plot(t[500:750], u_pred[500:750], alpha=0.75, lw=2, label='Predicho valid');\n",
    "    ax[1].plot(t[750:], u_pred[750:], alpha=0.75, lw=2, label='Predicho test'); ax[1].legend();\n",
    "\n",
    "    ax[2].plot(t[:500], (ymg[:500] - u_pred[:500])**2, label='Error cuadrático train'); \n",
    "    ax[2].plot(t[500:750], (ymg[500:750] - u_pred[500:750])**2, label='Error cuadrático valid');\n",
    "    ax[2].plot(t[750:], (ymg[750:] - u_pred[750:])**2, label='Error cuadrático test'); ax[2].legend();\n",
    "    fig.suptitle(\"\\u03C4= \"+str(17)+\",   L =\"+str(L)+\",   \\u03BC= \"+str(mu), fontsize=16)\n",
    "    \n",
    "    print(\"MSE entrenamiento %0.4f, validación %0.4f, prueba %0.4f\" %(NMSE(ymg[nlms.L:500], u_pred[nlms.L:500]), \n",
    "                                                NMSE(ymg[500:750], u_pred[500:750]),NMSE(ymg[750:], u_pred[750:])))\n",
    "\n",
    "interact(upd, mu=(0.0,1.0,0.01),L=(0,30,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mu=0.02\n",
    "\n",
    "- (L = 5): El MSE de entrenamiento está cercano a 1000, mientras que los de validación y prueba se muestran aproximados entre 333.\n",
    "\n",
    "- (L = 10): El MSE de entrenamiento es de 646.15, mientras que el de validación y pruebas son, respectivamente, 164.89 y 180.82\n",
    "\n",
    "- (L = 15): EL MSE de entrenamiento es de 636.8327, mientras que el de validación y prueba son de 147.781 y 151.2214 respectivamente\n",
    "\n",
    "- (L = 30): El MSE de entrenamiento es de 626.8830, mientras que el de validación y prueba son de 151.222 y 161.0010 respectivamente.\n",
    "\n",
    "El MSE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Repita el paso anterior para el caso $\\tau = 30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t_train, y_train), (t_valid, y_valid), (t_test, y_test), ymg, t = MackeyGlass(tau=30.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_lms(30.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando \n",
    "L = 20\n",
    "nlms = Filtro_NLMS(L=L , mu=0.02)\n",
    "\n",
    "# Entrenamiento\n",
    "u_pred = np.zeros(shape=(1000, ))\n",
    "for k in range(nlms.L, len(y_train)):\n",
    "    u_pred[k] = nlms.update(un=y_train[k-nlms.L:k],dn=y_train[k])\n",
    "\n",
    "# Prueba\n",
    "for k in range(len(y_train), len(y_valid)):\n",
    "    u_pred[k] = np.dot(nlms.w,y_valid[k-nlms.L:k])\n",
    "\n",
    "# Test\n",
    "for l in range(len(y_valid),len(y_test)):\n",
    "    u_pred[l] = np.dot(nlms.w,y_test[l-nlms.L:l])\n",
    "    \n",
    "print(\"NMSE entrenamiento %0.4f, validación %0.4f, prueba %0.4f\" %(NMSE(ymg[nlms.L:500], u_pred[nlms.L:500]), \n",
    "                                                NMSE(ymg[500:750], u_pred[500:750]),NMSE(ymg[750:], u_pred[750:])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upd(mu, L):\n",
    "    \n",
    "    fig, ax = plt.subplots(3, figsize=(9, 7), tight_layout=True)\n",
    "    (t_train, y_train), (t_valid, y_valid), (t_test, y_test),ymg,t = MackeyGlass(tau=30.)\n",
    "    nlms = Filtro_NLMS(L=L , mu=mu)\n",
    "\n",
    "    \n",
    "    u_pred = np.zeros(shape=(1000, ))\n",
    "    for k in range(nlms.L, len(y_train)):\n",
    "        u_pred[k] = nlms.update(un=y_train[k-nlms.L:k],dn=y_train[k])\n",
    "\n",
    "    for k in range(len(y_train), len(y_valid)):\n",
    "        u_pred[k] = np.dot(nlms.w,y_valid[k-nlms.L:k])\n",
    "\n",
    "    for l in range(len(y_valid),len(y_test)):\n",
    "        u_pred[l] = np.dot(nlms.w,y_test[l-nlms.L:l])\n",
    "\n",
    "\n",
    "    y = np.append(y_test, np.append(y_train, y_valid))\n",
    "\n",
    "    ax[0].plot(t ,y,'k.', alpha=0.5, label='Observado'); ax[0].legend(); \n",
    "    ax[1].plot(t , ymg, 'g-', alpha=0.5, lw=2, label='Intrínseco', c='y'); \n",
    "    ax[1].plot(t[:500], u_pred[:500], alpha=0.75, lw=2, label='Predicho train'); \n",
    "    ax[1].plot(t[500:750], u_pred[500:750], alpha=0.75, lw=2, label='Predicho valid');\n",
    "    ax[1].plot(t[750:], u_pred[750:], alpha=0.75, lw=2, label='Predicho test'); ax[1].legend();\n",
    "\n",
    "    ax[2].plot(t[:500], (ymg[:500] - u_pred[:500])**2, label='Error cuadrático train'); \n",
    "    ax[2].plot(t[500:750], (ymg[500:750] - u_pred[500:750])**2, label='Error cuadrático valid');\n",
    "    ax[2].plot(t[750:], (ymg[750:] - u_pred[750:])**2, label='Error cuadrático test'); ax[2].legend();\n",
    "    fig.suptitle(\"\\u03C4= \"+str(17)+\",   L =\"+str(L)+\",   \\u03BC= \"+str(mu), fontsize=16)\n",
    "    \n",
    "    print(\"MSE entrenamiento %0.4f, validación %0.4f, prueba %0.4f\" %(NMSE(ymg[nlms.L:500], u_pred[nlms.L:500]), \n",
    "                                                NMSE(ymg[500:750], u_pred[500:750]),NMSE(ymg[750:], u_pred[750:])))\n",
    "\n",
    "interact(upd, mu=(0.0,1.0,0.01),L=(0,30,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Compare los resultados obtenidos con cada serie de tiempo ($\\tau=17$ y $\\tau=30$). Muestre la predicción en el conjunto de prueba versus su valor real. Muestre también los residuos. Discuta y analice sus resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (45%) Predicción con algoritmo RLS\n",
    "\n",
    "1. Describa en detalle el algoritmo RLS e implemente un predictor a un paso basado en el algoritmo RLS. Resalte las diferencias con el algoritmo LMS\n",
    "1. Considere el caso $\\tau=17$. Entrene su predictor en el conjunto de entrenamiento y encuentre la combinación de parámetros $\\beta$ y $L$ que minimiza el NMSE en el conjunto de validación. Para $L$ pruebe al menos los siguientes valores [5, 10, 20, 30]. Comente sobre lo que observa.\n",
    "1. Repita el paso anterior para el caso $\\tau = 30$\n",
    "1. Compare los resultados obtenidos con cada serie de tiempo. Muestre la predicción en el conjunto de prueba versus su valor real. Muestre también los residuos. Discuta y analice sus resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Describa en detalle el algoritmo RLS e implemente un predictor a un paso basado en el algoritmo RLS. Resalte las diferencias con el algoritmo LMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor a un paso\n",
    "class Filtro_RLS:\n",
    "    \n",
    "    def __init__(self, L, beta=0.99, lamb=1e-2):\n",
    "        self.L = L\n",
    "        self.w = np.zeros(shape=(L, ))\n",
    "        self.beta = beta\n",
    "        self.lamb = lamb\n",
    "        self.Phi_inv = lamb*np.eye(L)\n",
    "        \n",
    "    def update(self, un, dn):\n",
    "        pi = np.dot(un.T, self.Phi_inv)\n",
    "        kn = pi.T/(self.beta + np.inner(pi, un))\n",
    "        error = dn - np.dot(self.w, un)\n",
    "        self.w += kn*error\n",
    "        self.Phi_inv = (self.Phi_inv - np.outer(kn, pi))*self.beta**-1\n",
    "        return np.dot(self.w, un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 20\n",
    "rls = Filtro_RLS(L=L)\n",
    "\n",
    "# Train\n",
    "u_pred = np.zeros(shape=(len(y_obs), ))\n",
    "\n",
    "for k in range(rls.L, 500):\n",
    "    u_pred[k] = rls.update(dn=y_train, un=y_train[k-rls.L:k])\n",
    "    \n",
    "# Valid\n",
    "for k in range(500, 750):\n",
    "    u_pred[k] = np.dot(rls.w,y_valid[k-rls.L:k])\n",
    "    \n",
    "# Test\n",
    "for k in range(750,1000):\n",
    "    u_pred[k] = np.dot(rls.w,y_obs[k-rls.L:k])\n",
    "    \n",
    "print(\"MSE entrenamiento %0.4f, valid %0.4f, prueba %0.4f\" %(NMSE(ymg[rls.L:500], u_pred[rls.L:500]), \n",
    "                                                              NMSE(ymg[500:750], u_pred[500:750]), \n",
    "                                                              NMSE(ymg[750:], u_pred[750:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Considere el caso $\\tau=17$. Entrene su predictor en el conjunto de entrenamiento y encuentre la combinación de parámetros $\\beta$ y $L$ que minimiza el NMSE en el conjunto de validación. Para $L$ pruebe al menos los siguientes valores [5, 10, 20, 30]. Comente sobre lo que observa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upd_rls(beta, L):\n",
    "    \n",
    "    fig, ax = plt.subplots(3, figsize=(9, 7), tight_layout=True)\n",
    "    (t_train, y_train), (t_valid, y_valid), (t_test, y_test) = MackeyGlass(tau=17.)\n",
    "    nlms = Filtro_RLS(L=L , beta=beta)\n",
    "\n",
    "    u_pred = np.zeros(shape=(len(y_obs), ))\n",
    "    u_pred = np.zeros(shape=(len(y_obs), ))\n",
    "\n",
    "    for k in range(rls.L, 500):\n",
    "        u_pred[k] = rls.update(dn=y_obs[k], un=y_obs[k-rls.L:k])\n",
    "\n",
    "    for k in range(500, 750):\n",
    "        u_pred[k] = np.dot(rls.w,y_obs[k-rls.L:k])\n",
    "\n",
    "    for k in range(750,1000):\n",
    "        u_pred[k] = np.dot(rls.w,y_obs[k-rls.L:k])\n",
    "    \n",
    "    ax[0].plot(t, y_obs, 'k.', alpha=0.5, label='Observado'); ax[0].legend(); \n",
    "    ax[1].plot(t, ymg, 'g-', alpha=0.5, lw=2, label='Intrínseco', c='y'); \n",
    "    ax[1].plot(t[:500], u_pred[:500], alpha=0.75, lw=2, label='Predicho train'); \n",
    "    ax[1].plot(t[500:750], u_pred[500:750], alpha=0.75, lw=2, label='Predicho valid');\n",
    "    ax[1].plot(t[750:], u_pred[750:], alpha=0.75, lw=2, label='Predicho test'); ax[1].legend();\n",
    "\n",
    "    ax[2].plot(t[:500], (ymg[:500] - u_pred[:500])**2, label='Error cuadrático train'); \n",
    "    ax[2].plot(t[500:750], (ymg[500:750] - u_pred[500:750])**2, label='Error cuadrático valid');\n",
    "    ax[2].plot(t[750:], (ymg[750:] - u_pred[750:])**2, label='Error cuadrático test'); ax[2].legend();\n",
    "    fig.suptitle(\"\\u03C4= \"+str(30)+\",   L =\"+str(L)+\",   \\u03B2= \"+str(beta), fontsize=16)\n",
    "    \n",
    "    print(\"MSE entrenamiento %0.4f, validación %0.4f, prueba %0.4f\" %(NMSE(ymg[nlms.L:500], u_pred[nlms.L:500]), \n",
    "                                                NMSE(ymg[500:750], u_pred[500:750]),NMSE(ymg[750:], u_pred[750:])))\n",
    "\n",
    "\n",
    "\n",
    "interact(upd_rls, beta=(0.0,1.0,0.01), L=(0,30,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3  Repita el paso anterior para el caso $\\tau = 30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b52b62d4fe3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0minteract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupd_rls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'interact' is not defined"
     ]
    }
   ],
   "source": [
    "def upd_rls(beta, L):\n",
    "    \n",
    "    fig, ax = plt.subplots(3, figsize=(9, 7), tight_layout=True)\n",
    "    (t_train, y_train), (t_valid, y_valid), (t_test, y_test) = MackeyGlass(tau=17.)\n",
    "    nlms = Filtro_RLS(L=L , beta=beta)\n",
    "\n",
    "    u_pred = np.zeros(shape=(len(y_obs), ))\n",
    "    u_pred = np.zeros(shape=(len(y_obs), ))\n",
    "\n",
    "    for k in range(rls.L, 500):\n",
    "        u_pred[k] = rls.update(dn=y_obs[k], un=y_obs[k-rls.L:k])\n",
    "\n",
    "    for k in range(500, 750):\n",
    "        u_pred[k] = np.dot(rls.w,y_obs[k-rls.L:k])\n",
    "\n",
    "    for k in range(750,1000):\n",
    "        u_pred[k] = np.dot(rls.w,y_obs[k-rls.L:k])\n",
    "    \n",
    "    ax[0].plot(t, y_obs, 'k.', alpha=0.5, label='Observado'); ax[0].legend(); \n",
    "    ax[1].plot(t, ymg, 'g-', alpha=0.5, lw=2, label='Intrínseco', c='y'); \n",
    "    ax[1].plot(t[:500], u_pred[:500], alpha=0.75, lw=2, label='Predicho train'); \n",
    "    ax[1].plot(t[500:750], u_pred[500:750], alpha=0.75, lw=2, label='Predicho valid');\n",
    "    ax[1].plot(t[750:], u_pred[750:], alpha=0.75, lw=2, label='Predicho test'); ax[1].legend();\n",
    "\n",
    "    ax[2].plot(t[:500], (ymg[:500] - u_pred[:500])**2, label='Error cuadrático train'); \n",
    "    ax[2].plot(t[500:750], (ymg[500:750] - u_pred[500:750])**2, label='Error cuadrático valid');\n",
    "    ax[2].plot(t[750:], (ymg[750:] - u_pred[750:])**2, label='Error cuadrático test'); ax[2].legend();\n",
    "    fig.suptitle(\"\\u03C4= \"+str(30)+\",   L =\"+str(L)+\",   \\u03B2= \"+str(beta), fontsize=16)\n",
    "    \n",
    "    print(\"MSE entrenamiento %0.4f, validación %0.4f, prueba %0.4f\" %(NMSE(ymg[nlms.L:500], u_pred[nlms.L:500]), \n",
    "                                                NMSE(ymg[500:750], u_pred[500:750]),NMSE(ymg[750:], u_pred[750:])))\n",
    "\n",
    "\n",
    "\n",
    "interact(upd_rls, beta=(0.0,1.0,0.01), L=(0,30,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Compare los resultados obtenidos con cada serie de tiempo. Muestre la predicción en el conjunto de prueba versus su valor real. Muestre también los residuos. Discuta y analice sus resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (10%) Comparación entre LMS y RLS\n",
    "\n",
    "1. Compare el mejor predictor LMS y RLS en el conjunto de test en términos de la calidad de la predicción y la velocidad a la que sigue los cambios. Comente y discuta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R: El algoritmo RLS el mucho mas rapido para converger que el algoritmo LMS, pero presentan problemas en la insertabilidad, y utilizacion de lenguaje mas complejo. Debido a que el algoritmo LMS considera solo el error cuadratico inmediato, contrario a RLS que utiliza un historial de errores, esto lo hace tener mayor calidad de prediccion y adaptacion a los cambios bruscos. El algoritmo LMS puede  ser una solución sencilla cuando se trabaja con  señales que cambian muy lentamente con el tiempo, ya que es lento para adaptarse y se desarrolla de forma lineal, en cambio el algoritmo RLS se desarrolla de forma recursiva."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
